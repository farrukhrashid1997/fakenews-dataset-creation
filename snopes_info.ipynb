{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the media bias data and JSON evidence data\n",
    "media_bias_path = 'media-bias/media-bias.csv'\n",
    "json_path = 'output/search_results_new_filtered.json'\n",
    "\n",
    "media_bias_df = pd.read_csv(media_bias_path)\n",
    "with open(json_path, 'r') as f:\n",
    "    evidence_data = json.load(f)\n",
    "\n",
    "\n",
    "def extract_base_domain(link):\n",
    "    if \"://\" in link:\n",
    "        domain = link.split(\"/\")[2]\n",
    "        return domain.lstrip(\"www.\")  # Remove 'www.' if present\n",
    "    return None\n",
    "\n",
    "# Update JSON evidence by refining and matching base domain\n",
    "for claim_id, claim_details in evidence_data.items():\n",
    "    for evidence in claim_details[\"evidence\"]:\n",
    "        refined_domain = extract_base_domain(evidence[\"link\"])\n",
    "        if refined_domain and any(refined_domain in base for base in media_bias_df['Group']):\n",
    "            matched_row = media_bias_df[media_bias_df['Group'].str.contains(refined_domain)].iloc[0]\n",
    "            evidence[\"MBFC Credibility Rating\"] = matched_row[\"MBFC Credibility Rating\"]\n",
    "            evidence[\"Bias Rating\"] = matched_row[\"Bias Rating\"]\n",
    "        else:\n",
    "            evidence[\"MBFC Credibility Rating\"] = None\n",
    "            evidence[\"Bias Rating\"] = None\n",
    "\n",
    "# Save the refined JSON file\n",
    "refined_json_path = 'output/search_results_mbfc_new.json'\n",
    "with open(refined_json_path, 'w') as f:\n",
    "    json.dump(evidence_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of links with ratings per ID: 10.217723453017571\n",
      "Average number of links with high ratings per ID: 8.115355233002292\n"
     ]
    }
   ],
   "source": [
    "def average_links_with_ratings(data):\n",
    "    total_links = 0\n",
    "    total_ids = 0\n",
    "\n",
    "    for id_key, id_value in data.items():\n",
    "        if \"evidence\" in id_value:\n",
    "            links_with_ratings = [\n",
    "                ev for ev in id_value[\"evidence\"] \n",
    "                if ev.get(\"MBFC Credibility Rating\") is not None and ev.get(\"Bias Rating\") is not None\n",
    "            ]\n",
    "            total_links += len(links_with_ratings)\n",
    "            total_ids += 1\n",
    "\n",
    "    return total_links / total_ids if total_ids > 0 else 0\n",
    "\n",
    "json_path = 'output/search_results_mbfc.json'\n",
    "with open(json_path, 'r') as f:\n",
    "    evidence_data = json.load(f)\n",
    "\n",
    "\n",
    "def average_high_credibility_links(data):\n",
    "    total_high_credibility_links = 0\n",
    "    total_ids = 0\n",
    "\n",
    "    for id_key, id_value in data.items():\n",
    "        if \"evidence\" in id_value:\n",
    "            high_credibility_links = [\n",
    "                ev for ev in id_value[\"evidence\"] \n",
    "                if ev.get(\"MBFC Credibility Rating\") == \"HIGH CREDIBILITY\"\n",
    "            ]\n",
    "            total_high_credibility_links += len(high_credibility_links)\n",
    "            total_ids += 1\n",
    "\n",
    "    return total_high_credibility_links / total_ids if total_ids > 0 else 0\n",
    "\n",
    "\n",
    "# Calculate and print the average\n",
    "average = average_links_with_ratings(evidence_data)\n",
    "high_cred_avg = average_high_credibility_links(evidence_data)\n",
    "print(f\"Average number of links with ratings per ID: {average}\")\n",
    "print(f\"Average number of links with high ratings per ID: {high_cred_avg}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evidence links filtered by similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/search_results_latest.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Processing the data\n",
    "result = []\n",
    "\n",
    "for claim_id, claim_data in data.items():\n",
    "    evidence_links = [evidence['link'] for evidence in claim_data['evidence']]\n",
    "    evidence_links_similar = [\n",
    "        evidence['link'] for evidence in claim_data['evidence'] if evidence['similarity_score'] >= 0.75\n",
    "    ]\n",
    "    result.append({\n",
    "        \"claimid\": claim_id,\n",
    "        \"evidence_links_count\": len(evidence_links),\n",
    "        \"evidence_links_similar_count\": len(evidence_links_similar)\n",
    "    })\n",
    "\n",
    "# Output result\n",
    "\n",
    "with open('output/evidence_links_filtered_by_similarity_score.json', 'w') as f:\n",
    "    json.dump(result, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output/high_impact_claims.json'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Read the CSV file\n",
    "file_path = 'output/snopes_results_latest.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter rows with Impact Score > 8\n",
    "filtered_data = data[data['Impact Score'] >= 8]\n",
    "\n",
    "# Prepare the JSON structure\n",
    "result = [\n",
    "    {\n",
    "        \"claim\": row['claim'],\n",
    "        \"impact score\": row['Impact Score'],\n",
    "        \"impact justification\": row['Impact Justification']\n",
    "    }\n",
    "    for _, row in filtered_data.iterrows()\n",
    "]\n",
    "print(len(result))\n",
    "# Write the result to a JSON file\n",
    "output_file_path = 'output/high_impact_claims.json'\n",
    "with open(output_file_path, 'w') as json_file:\n",
    "    json.dump(result, json_file, indent=4)\n",
    "\n",
    "output_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fnd-dataset-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
